{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ef0447-50f5-4341-8773-3273b86f4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
    "%matplotlib inline\n",
    "from tensorflow.keras import Model\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e4905-0c88-478c-9ad6-6431bfe83c4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c645d6d6-deb1-4c47-90d0-0372c6db405c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the directory of the current script\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define the paths\n",
    "model_path = 'IRV2+SA.hdf5'\n",
    "test_path = os.path.join(cwd,'../','data', 'collected')\n",
    "classes_path = os.path.join(cwd,'../','data', 'collected_by_class')\n",
    "\n",
    "# List all files in the collected folder\n",
    "files = os.listdir(test_path)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4882841f-3d38-4b74-8221-77919e1b64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(classes_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b792d9b-c427-4b6a-8329-ff4d9a00ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create directories and move files\n",
    "def organize_files_by_digit(base_path, out_path):\n",
    "    files = os.listdir(base_path)\n",
    "    for file in files:\n",
    "        if '_' in file:\n",
    "            src = os.path.join(base_path, file)\n",
    "            # Skip directories\n",
    "            if os.path.isdir(src):\n",
    "                continue\n",
    "            # Extract the first digit after the underscore\n",
    "            first_digit = file.split('_')[1][0]\n",
    "            # Create a new directory for this digit if it doesn't exist\n",
    "            digit_folder = os.path.join(out_path, first_digit)\n",
    "            os.makedirs(digit_folder, exist_ok=True)\n",
    "            # Move the file to the new directory\n",
    "            dst = os.path.join(digit_folder, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "# Organize the files\n",
    "organize_files_by_digit(test_path,classes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af8c7e4-13bb-4b62-8e2e-ca7f636f979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Attention\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
    "        self.channels=int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "\n",
    "        \n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.i_shape = input_shape\n",
    "\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "    \n",
    "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "\n",
    "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "        \n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                        initializer='he_uniform',\n",
    "                                        name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        exp_x = K.expand_dims(x,axis=-1)\n",
    "\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d,\n",
    "                        self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
    "\n",
    "        \n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
    "\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
    "   \n",
    "            x_exp = K.expand_dims(x,axis=-2)\n",
    "   \n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
    "  \n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
    "\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
    "\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
    "\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u,x])\n",
    "        else:\n",
    "            o = u\n",
    "        \n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(SoftAttention,self).get_config()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58eec34-7238-485b-903f-a4f8bf8db89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 10:40:43.502225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.507367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.507529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.508374: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 10:40:43.509053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.509223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.509369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.886265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.886460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.886602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-24 10:40:43.886712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10381 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "irv2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\n",
    ")\n",
    "\n",
    "# Excluding the last 28 layers of the model.\n",
    "conv = irv2.layers[-28].output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a87aa54-99c2-4430-99d9-aa228ef81488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0adeb14d-f449-4708-b909-75c0107c0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=irv2.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5895f0aa-6af1-4e68-8f5c-6c403d374df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the model\n",
    "#model = load_model(model_path)\n",
    "model.load_weights(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c167207-bdaf-428f-b452-75d518f8e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bccf442-8c2e-4122-9757-a3b45df4a362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Batches: \n",
      "Found 121 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define image properties\n",
    "#img_width, img_height = 600, 450  # Assume InceptionResNetV2 default input size\n",
    "image_size = 299\n",
    "batch_size = 16\n",
    "# Define data generator for validation data\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(classes_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c3233b-b695-412c-b2a1-be4e54ad21c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 10:40:47.607039: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-07-24 10:40:49.422509: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2024-07-24 10:40:49.593472: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-24 10:40:49.594172: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-24 10:40:49.594226: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2024-07-24 10:40:49.595021: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-24 10:40:49.595092: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_batches, steps=len(files)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b1c3550-be76-49ca-bba6-2df2f84afa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 4, 0, 4, 1, 2, 0, 0, 2, 4, 2, 4, 2, 1, 5, 1, 3,\n",
       "       1, 5, 6, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 4, 1, 5, 1, 4,\n",
       "       1, 1, 1, 1, 0, 2, 0, 4, 5, 4, 0, 1, 1, 1, 1, 2, 4, 3, 1, 0, 4, 1,\n",
       "       1, 1, 1, 2, 5, 2, 0, 0, 5, 5, 1, 4, 5, 5, 4, 2, 0, 5, 3, 5, 5, 1,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 4, 4, 0, 0, 4, 4, 5,\n",
       "       2, 5, 4, 4, 4, 2, 5, 2, 4, 5, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16939faf-2fa3-4212-a736-b2ad5893ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.39      0.54      0.45        13\n",
      "         bcc       0.81      0.47      0.60        55\n",
      "         bkl       0.20      0.21      0.21        14\n",
      "          df       0.33      0.20      0.25         5\n",
      "         mel       0.09      0.12      0.10        17\n",
      "          nv       0.10      0.20      0.13        15\n",
      "        vasc       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35       121\n",
      "   macro avg       0.28      0.25      0.25       121\n",
      "weighted avg       0.47      0.35      0.39       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image \n",
    "y_true = test_batches.classes\n",
    "#getting the predicted labels per image \n",
    "y_prob=predictions\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_true)\n",
    "\n",
    "# Creating classification report \n",
    "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f47a98-45fb-472f-b235-8fca07747524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4731832790717088\n",
      "Recall: 0.34710743801652894\n",
      "Accuracy: 0.34710743801652894\n",
      "weighted Roc score: 0.7087370175489075\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"weighted Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f564d60-f76d-4e0b-9c58-9f157f7a605b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
